{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "# 학습률\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npz 파일 로딩\n",
    "data = np.load('./data/cat_dog.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[106, 136, 119],\n",
       "         [143, 181, 192],\n",
       "         [114,  95,  76],\n",
       "         ...,\n",
       "         [134, 122,  69],\n",
       "         [140, 128,  84],\n",
       "         [158, 145, 112]],\n",
       "\n",
       "        [[ 98, 119,  99],\n",
       "         [146, 180, 188],\n",
       "         [125, 105,  82],\n",
       "         ...,\n",
       "         [135, 120,  68],\n",
       "         [144, 130,  87],\n",
       "         [163, 150, 118]],\n",
       "\n",
       "        [[ 99, 111,  87],\n",
       "         [159, 191, 196],\n",
       "         [126, 111,  86],\n",
       "         ...,\n",
       "         [134, 115,  67],\n",
       "         [150, 134,  93],\n",
       "         [163, 149, 120]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  6,   7,  11],\n",
       "         [  5,   5,   6],\n",
       "         [  8,   5,   3],\n",
       "         ...,\n",
       "         [135, 166, 160],\n",
       "         [139, 170, 165],\n",
       "         [141, 170, 165]],\n",
       "\n",
       "        [[ 12,  10,  13],\n",
       "         [ 17,  14,  13],\n",
       "         [ 17,  11,   7],\n",
       "         ...,\n",
       "         [124, 153, 145],\n",
       "         [132, 157, 152],\n",
       "         [137, 152, 152]],\n",
       "\n",
       "        [[ 18,  14,   9],\n",
       "         [ 23,  21,  15],\n",
       "         [ 20,  17,   9],\n",
       "         ...,\n",
       "         [ 45,  67,  63],\n",
       "         [ 47,  63,  61],\n",
       "         [ 47,  57,  59]]],\n",
       "\n",
       "\n",
       "       [[[212, 210, 198],\n",
       "         [171, 170, 159],\n",
       "         [238, 238, 230],\n",
       "         ...,\n",
       "         [ 59,  42,  35],\n",
       "         [ 63,  48,  45],\n",
       "         [ 60,  45,  44]],\n",
       "\n",
       "        [[215, 213, 201],\n",
       "         [166, 165, 154],\n",
       "         [238, 238, 229],\n",
       "         ...,\n",
       "         [ 61,  43,  37],\n",
       "         [ 64,  49,  46],\n",
       "         [ 59,  44,  43]],\n",
       "\n",
       "        [[225, 223, 211],\n",
       "         [163, 163, 152],\n",
       "         [232, 234, 224],\n",
       "         ...,\n",
       "         [ 63,  46,  40],\n",
       "         [ 65,  51,  47],\n",
       "         [ 57,  43,  41]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[177, 143, 143],\n",
       "         [164, 133, 133],\n",
       "         [143, 114, 115],\n",
       "         ...,\n",
       "         [ 80,  80,  80],\n",
       "         [ 72,  72,  72],\n",
       "         [ 64,  64,  64]],\n",
       "\n",
       "        [[162, 121, 117],\n",
       "         [167, 127, 125],\n",
       "         [167, 134, 133],\n",
       "         ...,\n",
       "         [ 81,  81,  81],\n",
       "         [ 76,  76,  76],\n",
       "         [ 73,  73,  73]],\n",
       "\n",
       "        [[ 94,  50,  45],\n",
       "         [ 83,  41,  37],\n",
       "         [ 72,  37,  33],\n",
       "         ...,\n",
       "         [ 33,  33,  33],\n",
       "         [ 21,  21,  21],\n",
       "         [ 20,  20,  20]]],\n",
       "\n",
       "\n",
       "       [[[111,  93,  89],\n",
       "         [112,  94,  91],\n",
       "         [114,  96,  92],\n",
       "         ...,\n",
       "         [ 83,  77,  76],\n",
       "         [ 84,  78,  78],\n",
       "         [ 87,  81,  81]],\n",
       "\n",
       "        [[115,  97,  92],\n",
       "         [115,  98,  92],\n",
       "         [115,  98,  92],\n",
       "         ...,\n",
       "         [ 84,  78,  77],\n",
       "         [ 83,  77,  78],\n",
       "         [ 86,  80,  80]],\n",
       "\n",
       "        [[118, 101,  93],\n",
       "         [118, 101,  93],\n",
       "         [118, 101,  93],\n",
       "         ...,\n",
       "         [ 84,  79,  78],\n",
       "         [ 83,  77,  77],\n",
       "         [ 83,  77,  77]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[252, 141, 220],\n",
       "         [252, 141, 220],\n",
       "         [254, 144, 223],\n",
       "         ...,\n",
       "         [251, 142, 221],\n",
       "         [252, 143, 222],\n",
       "         [253, 144, 223]],\n",
       "\n",
       "        [[251, 141, 220],\n",
       "         [251, 141, 220],\n",
       "         [254, 145, 224],\n",
       "         ...,\n",
       "         [250, 142, 221],\n",
       "         [251, 143, 221],\n",
       "         [251, 143, 221]],\n",
       "\n",
       "        [[252, 144, 223],\n",
       "         [250, 141, 220],\n",
       "         [251, 142, 221],\n",
       "         ...,\n",
       "         [249, 142, 220],\n",
       "         [249, 142, 220],\n",
       "         [250, 143, 221]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 86,  79,  61],\n",
       "         [ 86,  79,  61],\n",
       "         [ 87,  80,  62],\n",
       "         ...,\n",
       "         [ 41,  35,  35],\n",
       "         [ 40,  34,  34],\n",
       "         [ 39,  33,  33]],\n",
       "\n",
       "        [[ 77,  70,  52],\n",
       "         [ 77,  70,  52],\n",
       "         [ 78,  71,  53],\n",
       "         ...,\n",
       "         [ 44,  38,  38],\n",
       "         [ 42,  36,  36],\n",
       "         [ 44,  38,  38]],\n",
       "\n",
       "        [[ 76,  69,  51],\n",
       "         [ 76,  69,  51],\n",
       "         [ 76,  69,  51],\n",
       "         ...,\n",
       "         [ 50,  44,  44],\n",
       "         [ 46,  40,  40],\n",
       "         [ 46,  40,  40]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[162, 150, 126],\n",
       "         [159, 146, 123],\n",
       "         [159, 146, 124],\n",
       "         ...,\n",
       "         [202, 206, 232],\n",
       "         [203, 207, 232],\n",
       "         [204, 208, 234]],\n",
       "\n",
       "        [[134, 125, 104],\n",
       "         [123, 115,  94],\n",
       "         [121, 113,  94],\n",
       "         ...,\n",
       "         [203, 206, 237],\n",
       "         [201, 204, 234],\n",
       "         [200, 204, 233]],\n",
       "\n",
       "        [[169, 163, 144],\n",
       "         [168, 163, 144],\n",
       "         [176, 170, 154],\n",
       "         ...,\n",
       "         [205, 208, 241],\n",
       "         [201, 203, 236],\n",
       "         [190, 193, 225]]],\n",
       "\n",
       "\n",
       "       [[[ 20,  19,  17],\n",
       "         [ 27,  26,  24],\n",
       "         [ 29,  28,  26],\n",
       "         ...,\n",
       "         [161, 149, 125],\n",
       "         [161, 149, 125],\n",
       "         [160, 148, 124]],\n",
       "\n",
       "        [[ 22,  21,  19],\n",
       "         [ 31,  30,  28],\n",
       "         [ 33,  32,  30],\n",
       "         ...,\n",
       "         [163, 151, 127],\n",
       "         [163, 151, 127],\n",
       "         [162, 150, 126]],\n",
       "\n",
       "        [[ 27,  26,  24],\n",
       "         [ 35,  34,  32],\n",
       "         [ 38,  37,  35],\n",
       "         ...,\n",
       "         [166, 154, 130],\n",
       "         [165, 153, 129],\n",
       "         [165, 153, 129]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[164, 148, 125],\n",
       "         [165, 149, 126],\n",
       "         [167, 151, 128],\n",
       "         ...,\n",
       "         [ 41,  68,  79],\n",
       "         [ 38,  65,  76],\n",
       "         [ 40,  67,  78]],\n",
       "\n",
       "        [[160, 144, 121],\n",
       "         [162, 146, 123],\n",
       "         [164, 148, 125],\n",
       "         ...,\n",
       "         [ 40,  67,  78],\n",
       "         [ 37,  64,  75],\n",
       "         [ 42,  69,  80]],\n",
       "\n",
       "        [[157, 141, 118],\n",
       "         [159, 143, 120],\n",
       "         [163, 147, 124],\n",
       "         ...,\n",
       "         [ 38,  65,  76],\n",
       "         [ 36,  63,  74],\n",
       "         [ 44,  71,  82]]],\n",
       "\n",
       "\n",
       "       [[[201, 204, 211],\n",
       "         [201, 204, 211],\n",
       "         [201, 204, 211],\n",
       "         ...,\n",
       "         [196, 199, 204],\n",
       "         [197, 200, 205],\n",
       "         [198, 201, 206]],\n",
       "\n",
       "        [[203, 206, 213],\n",
       "         [203, 206, 213],\n",
       "         [203, 206, 213],\n",
       "         ...,\n",
       "         [194, 197, 202],\n",
       "         [194, 197, 202],\n",
       "         [195, 198, 203]],\n",
       "\n",
       "        [[205, 208, 215],\n",
       "         [205, 208, 215],\n",
       "         [205, 208, 215],\n",
       "         ...,\n",
       "         [195, 198, 203],\n",
       "         [193, 196, 201],\n",
       "         [193, 196, 201]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[202, 205, 210],\n",
       "         [200, 203, 208],\n",
       "         [201, 204, 209],\n",
       "         ...,\n",
       "         [186, 190, 191],\n",
       "         [184, 188, 189],\n",
       "         [184, 188, 189]],\n",
       "\n",
       "        [[202, 205, 210],\n",
       "         [200, 203, 208],\n",
       "         [201, 204, 209],\n",
       "         ...,\n",
       "         [186, 190, 191],\n",
       "         [186, 190, 191],\n",
       "         [186, 190, 191]],\n",
       "\n",
       "        [[202, 205, 210],\n",
       "         [200, 203, 208],\n",
       "         [201, 204, 209],\n",
       "         ...,\n",
       "         [186, 190, 191],\n",
       "         [186, 190, 191],\n",
       "         [186, 190, 191]]]], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 224, 224, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 224, 224, 3), (500, 224, 224, 3), (1000, 224, 224, 3))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델링\n",
    "- conv레이어, pooling 레이어 활용 모델링\n",
    "- loss, val_loss 그래프 시각화\n",
    "- test 데이터 evaluate 결과 카톡에 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model = Sequential()\n",
    "\n",
    "# # 출력층-이진분류니까 다르게 해줘야함\n",
    "# # 1.특징추출부\n",
    "# cnn_model.add(Conv2D(input_shape = (224, 224, 3),\n",
    "#                     filters = 20,\n",
    "#                      kernel_size = (9,9),\n",
    "#                      activation = \"relu\"\n",
    "#                     ))\n",
    "# cnn_model.add(MaxPool2D())\n",
    "\n",
    "# cnn_model.add(Conv2D(filters = 20, # number of magnifying glasses(MG)\n",
    "#                     # thus, the more you bring MG, the more diverse features will be extracted\n",
    "#                     kernel_size = (3, 3), # the size of MG  : 3 * 3 = 9\n",
    "#                     activation = \"relu\"\n",
    "#                     ))\n",
    "# cnn_model.add(MaxPool2D())\n",
    "\n",
    "# # 2. classifier => MLP (추출된 특징으로 분류)\n",
    "# cnn_model.add(Flatten()) # layer that makes data with 1 dimension (simplication)\n",
    "# cnn_model.add(Dense(512, activation = \"relu\"))\n",
    "# cnn_model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "# # 1.특징추출부\n",
    "# cnn_model.add(Conv2D(input_shape = (224, 224, 3),\n",
    "#                     filters = 64,\n",
    "#                      kernel_size = (5,5),\n",
    "#                      padding =\"same\",\n",
    "#                      activation = \"relu\"\n",
    "#                     ))\n",
    "# cnn_model.add(MaxPool2D())\n",
    "\n",
    "# #\n",
    "# cnn_model.add(Conv2D(input_shape = (224, 224, 3),\n",
    "#                     filters = 128,\n",
    "#                      kernel_size = (5,5),\n",
    "#                      padding =\"same\",\n",
    "#                      activation = \"relu\"\n",
    "#                     ))\n",
    "# cnn_model.add(MaxPool2D())\n",
    "\n",
    "# cnn_model.add(Conv2D(input_shape = (224, 224, 3),\n",
    "#                     filters = 64,\n",
    "#                      kernel_size = (5,5),\n",
    "#                      padding =\"same\",\n",
    "#                      activation = \"relu\"\n",
    "#                     ))\n",
    "# cnn_model.add(MaxPool2D())\n",
    "\n",
    "cnn_model.add(Conv2D(input_shape = (224, 224, 3),\n",
    "                    filters = 32,\n",
    "                     kernel_size = (13,13),\n",
    "                     padding =\"same\",\n",
    "                     activation = \"relu\"\n",
    "                    ))\n",
    "cnn_model.add(MaxPool2D())\n",
    "\n",
    "cnn_model.add(Conv2D(input_shape = (224, 224, 3),\n",
    "                    filters = 64,\n",
    "                     kernel_size = (13,13),\n",
    "                     padding =\"same\",\n",
    "                     activation = \"relu\"\n",
    "                    ))\n",
    "cnn_model.add(MaxPool2D())\n",
    "\n",
    "cnn_model.add(Conv2D(input_shape = (224, 224, 3),\n",
    "                    filters = 128,\n",
    "                     kernel_size = (13,13),\n",
    "                     padding =\"same\",\n",
    "                     activation = \"relu\"\n",
    "                    ))\n",
    "cnn_model.add(MaxPool2D())\n",
    "\n",
    "\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 128, # number of magnifying glasses(MG)\n",
    "                    # thus, the more you bring MG, the more diverse features will be extracted\n",
    "                    kernel_size = (5, 5), # the size of MG  : 3 * 3 = 9\n",
    "                    activation = \"relu\"\n",
    "                    ))\n",
    "cnn_model.add(MaxPool2D())\n",
    "\n",
    "# 2. classifier => MLP (추출된 특징으로 분류)\n",
    "\n",
    "cnn_model.add(Flatten()) # layer that makes data with 1 dimension (simplication)\n",
    "cnn_model.add(Dense(4096, activation = \"relu\")) # 뉴런수, 필터으 ㅣ거듭 제곱으로 늘린다.\n",
    "cnn_model.add(Dense(1, activation = \"sigmoid\")) # 출력층-이진분류니까 다르게 해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate=0.0001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_83 (Conv2D)           (None, 224, 224, 32)      16256     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 112, 112, 64)      346176    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 56, 56, 128)       1384576   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 24, 24, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 4096)              75501568  \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 77,662,401\n",
      "Trainable params: 77,662,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.4528 - accuracy: 0.8027 - val_loss: 0.6721 - val_accuracy: 0.6020\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.3759 - accuracy: 0.8280 - val_loss: 0.6236 - val_accuracy: 0.6720\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.2429 - accuracy: 0.9127 - val_loss: 0.7297 - val_accuracy: 0.6920\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.1497 - accuracy: 0.9560 - val_loss: 0.8145 - val_accuracy: 0.6780\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.1062 - accuracy: 0.9673 - val_loss: 0.9768 - val_accuracy: 0.6500\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.0402 - accuracy: 0.9960 - val_loss: 1.0200 - val_accuracy: 0.6920\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.7040\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3052 - val_accuracy: 0.7080\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4200 - val_accuracy: 0.6940\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 9.7648e-04 - accuracy: 1.0000 - val_loss: 1.4717 - val_accuracy: 0.7080\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 7.2205e-04 - accuracy: 1.0000 - val_loss: 1.5287 - val_accuracy: 0.7020\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 5.7059e-04 - accuracy: 1.0000 - val_loss: 1.5662 - val_accuracy: 0.7040\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 4.6634e-04 - accuracy: 1.0000 - val_loss: 1.6000 - val_accuracy: 0.7060\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 3.9347e-04 - accuracy: 1.0000 - val_loss: 1.6415 - val_accuracy: 0.7020\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 3.3128e-04 - accuracy: 1.0000 - val_loss: 1.6690 - val_accuracy: 0.7000\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.8730e-04 - accuracy: 1.0000 - val_loss: 1.6867 - val_accuracy: 0.7040\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.5228e-04 - accuracy: 1.0000 - val_loss: 1.7147 - val_accuracy: 0.7040\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.2391e-04 - accuracy: 1.0000 - val_loss: 1.7371 - val_accuracy: 0.7020\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.0036e-04 - accuracy: 1.0000 - val_loss: 1.7643 - val_accuracy: 0.7040\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 1.7813e-04 - accuracy: 1.0000 - val_loss: 1.7784 - val_accuracy: 0.7040\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 1.6168e-04 - accuracy: 1.0000 - val_loss: 1.8037 - val_accuracy: 0.7000\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 1.4705e-04 - accuracy: 1.0000 - val_loss: 1.8173 - val_accuracy: 0.7040\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 1.3186e-04 - accuracy: 1.0000 - val_loss: 1.8330 - val_accuracy: 0.6960\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 1.2099e-04 - accuracy: 1.0000 - val_loss: 1.8508 - val_accuracy: 0.7020\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 1.1103e-04 - accuracy: 1.0000 - val_loss: 1.8651 - val_accuracy: 0.7020\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 1.0206e-04 - accuracy: 1.0000 - val_loss: 1.8846 - val_accuracy: 0.6960\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 9.4131e-05 - accuracy: 1.0000 - val_loss: 1.8954 - val_accuracy: 0.6980\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 8.7083e-05 - accuracy: 1.0000 - val_loss: 1.9112 - val_accuracy: 0.6960\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 8.0993e-05 - accuracy: 1.0000 - val_loss: 1.9259 - val_accuracy: 0.6940\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 7.6230e-05 - accuracy: 1.0000 - val_loss: 1.9405 - val_accuracy: 0.6920\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 6.9601e-05 - accuracy: 1.0000 - val_loss: 1.9564 - val_accuracy: 0.6940\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 6.4872e-05 - accuracy: 1.0000 - val_loss: 1.9671 - val_accuracy: 0.6940\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 6.0932e-05 - accuracy: 1.0000 - val_loss: 1.9774 - val_accuracy: 0.6940\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 5.7150e-05 - accuracy: 1.0000 - val_loss: 1.9914 - val_accuracy: 0.6940\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 5.3201e-05 - accuracy: 1.0000 - val_loss: 2.0028 - val_accuracy: 0.6940\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 4.9835e-05 - accuracy: 1.0000 - val_loss: 2.0166 - val_accuracy: 0.6940\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 4.7156e-05 - accuracy: 1.0000 - val_loss: 2.0259 - val_accuracy: 0.6940\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 4.4295e-05 - accuracy: 1.0000 - val_loss: 2.0391 - val_accuracy: 0.6940\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 4.1869e-05 - accuracy: 1.0000 - val_loss: 2.0460 - val_accuracy: 0.6960\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 3.9505e-05 - accuracy: 1.0000 - val_loss: 2.0633 - val_accuracy: 0.6920\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 3.7181e-05 - accuracy: 1.0000 - val_loss: 2.0693 - val_accuracy: 0.6920\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 3.5521e-05 - accuracy: 1.0000 - val_loss: 2.0801 - val_accuracy: 0.6900\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 3.3311e-05 - accuracy: 1.0000 - val_loss: 2.0909 - val_accuracy: 0.6920\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 3.1515e-05 - accuracy: 1.0000 - val_loss: 2.1062 - val_accuracy: 0.6940\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.9799e-05 - accuracy: 1.0000 - val_loss: 2.1124 - val_accuracy: 0.6940\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.8587e-05 - accuracy: 1.0000 - val_loss: 2.1217 - val_accuracy: 0.6900\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.7000e-05 - accuracy: 1.0000 - val_loss: 2.1324 - val_accuracy: 0.6940\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.5556e-05 - accuracy: 1.0000 - val_loss: 2.1428 - val_accuracy: 0.6940\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.4214e-05 - accuracy: 1.0000 - val_loss: 2.1542 - val_accuracy: 0.6940\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/sample - loss: 2.3111e-05 - accuracy: 1.0000 - val_loss: 2.1645 - val_accuracy: 0.6940\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(X_train,\n",
    "                       y_train,\n",
    "                        validation_data = (X_val, y_val),\n",
    "                        epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 880us/sample - loss: 1.9822 - accuracy: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9821820907592773, 0.705]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
