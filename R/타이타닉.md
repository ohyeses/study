- train 학습용 데이터
- test 테스트용 데이터
- submission 제출용 데이터

train 과 test 데이터를 통해 학습을 진행하고
나머지 예측값 을 gender_submission 파일 에 담아서 케글 사이트에 제출.
케글 사이트 내에 실제 데이터와 정확도가 몇인지 평가.

- 생존자와 사망자를 예측. <- 본질적인 목표 
- pt1 에 나온 평균들로 결측치를 채운다.
- 결측치 맘대로 채운는게 아니다.
- 너무 간단하게 안채우고, age와 가장 관계가 깊은 Pclass와 성별을 통해 그 곳의 사람의 나이 평균을 구해서 결측치를 채우겠다.
- 전처리 과정은 사람마다 다르다.  이렇게 해서 정확도가 높아질까요? 그거는 아무도 모른다.
- 왜 Ticket Embarked는 상관계수가 없나요 ? 수치화된 값이 아니기 때문에 
- 상관계수는 숫자형 자료일 때만 상관계수를 구할 수 있어서 수치형 데이터만 상관계수로서 나온다.

# Age 채우기
- df 데이터 프레임이 들어오고 나서, train의 Age 컬럼이, Age 컬럼에 결측치가 존재한다면 -> np.isnan(train['Age'])
- 결측치인건 True로 나오고 아닌건 False로 나온다.
- 결측치면 반환해준다. pt1에서 Pclass 값과 Sex 값
- 결측치인 Age 행에 맞는 Pclass와 성별이 들어가게 됨으로써 그거에 맞는 Age 평균값이 리턴이 된다.
- apply() 함수를 쓰면 우리가 직접 만든 함수 (def fill_age)를 쉽게 적용시켜 준다.
- axis=1 로 두면 행이 아니라 열로써 진행된다.

- train을 채웠으면 test도 결측치를 채워야 한다.
- test의결측치를 채워주고 나니 age의 타입을 보니 object로 변했다. (원래 int)
- 이걸 int로 바꿔야 하는데 바꾸기 보다는, 결측치를 채워줄 때, int형으로 바꿔주고 채운다. ->astype()
- ★항상 학습할 때 train 데이터와 test 데이터는 똑같아야 한다. 데이터 타입이든 뭐든, 그래야 비교할 수 가 있다.


# Embarked 채우기
- 어떤 타입으로 되어있는지 value_counts 를 쓴다.
- value_counts -> 데이터가 몇개씩 있는지 알려주는 함수 
- 결측치가 2개이기 때문에 어떤 값을 넣든 큰 변화는 없다.
- 그래서 Age 처럼 복잡하게 결측치를 채우지 않고 embarked에서는 제일 많은 값(S)로 결측치를 채운다.
- fillNa 함수를 사용한다. 
- ex)train['Embarked'].fillna('S') <- 결측치를 소괄호 안에 있는 값으로 채워준다.
- 실제로 적용되려면 채운 값을 train['Embarked']에 넣어줘야한다.
- Embarked 는 train 데이터에서만 발생한 결측치이다. test에는 결측치가 없으니 하지 않아도 된다.

# Fare 채우기
- test 데이터에 결측치가 있다.
- 수치형 데이터의 value_counts를 찍으면 길이가 너무나도 많다.
- 그래서 test['Fare'].mean()으로 평균값을 구한다.
- 간단하게 한 이유는 Fare 결측치도 한 개 밖에 없다.
- 그래서 결측치를 어떤 값으로 채워도 큰 영향을 미치지 않는다. -> 평균값으로 채운다.

# Cabin 채우기
- Cabin도 어떻게 생겨먹었는지 value_counts로 확인을 한다.
- 그냥 결측치로서의 의미로 나둔다.
- 그래서 여기 중에 없는거 train['Cabin'].fillna('N')을 새로운 컬럼(Deck)에 넣는다, 테스트에도 똑같이.
- 만약에 N을 넣으면 N의 개수가 많아질 거다. (채우고나니 687개가 되었다.)
- 687개나 되는 데이터를 다른 데이터로 결측치를 채워주는게 아니라, N이라는 데이터로 687개를 몰아준거다. 그러면 이 데이터는 다른 애 한테 영향을 끼치지 않는다. ==> 결측치로서의 의미 
- 4개를 20개로 바꾸고 그런게 아니라 결측치로서의 의미로 담아준것이다.
- 채운이 값을 새로운 열로 만들었으니까 Cabin 열을 날려버린다.


### EDA (Exploratory Data Analysis) 탐색적 데이터 분석. 탐색
- 전처리를 하고난 후(결측치 채워준 후)에 데이터 탐색 하기.
- train 데이터 탐색한다. 왜? test를 탐색하는 것은 모델 일반화에 도움이 되지 않는다.
- test는 평가하는 모델이기 때문에 train을 탐색한다.
- EDA 작업 하는 이유? 어떤 열과 어떤 열을 탐색해봄으로써, 내가 모르는 새로운 정보를 도출해 내는 과정이다.
- 우리가 Pclass와 Survived(생존)과의 그래프화를 통해 Pclass 3등석인 사람들이 많이 죽었구나 라는걸 도출해 냈다.
- 어떤열과 어떤열간의 관계를 계속해서 그래프화 시킴으로써 우리가 모르고 있는 새로운 정보를 얻는 과정이다.
- 정답이 없다. 여러분들이 하고싶은대로 하는거다.
- 시각화 함으로써 모르는 과정을 도출해내는 과정이라고 할 수 있다.


#### Deck 시각화
- snscountplot을 사용하여 그래프화 한다. 
- 죽음은 0 생존은 1
- N에서 상대적으로 사람이 많이 죽었다.


#### Pclass 시각화
- data는 train 데이터 사용, X축은 Pclass, Y축은 count, hue 는 범주(범례)
- 3등석인 사람이 많이 적었다. 생존자는 비슷.


#### Deck과 Pclass 간의 시각화 (잘 안보여서 안함.)

# Question2
- 성별과 생존과의 관계
- Embarked와 생존과의 관계를 시각화 해보자. snscountplot을 통해.
- data는 train 데이터, x축은 성별, hue(범례)는 survived -> 남자가 여자보다 많이 죽었다.
- data는 train 데이터, x축은 embarked, hue(범례)는 survived -> Embarked가 S에 해당하는 사람이 많이 죽었다.

## 수치형 데이터 시각화
### age 시각화
- plt.figure(figsize) 로 도화지 그리기.
- violin. 그래프 모양이 바이올린 모양으로 생겼다.
- 20~40대 사이의 사람이 많이 사망했다.
- 10세 이하 중에서는 남자아이가 여자아이에 비해 많이 살아있다.

### Fare 시각화 
- plt.figure(figsize) 로 도화지 그리기.
- y 축을 Fare로 바꾼다.
- 요금이 0부터 100사이 (싼사람)의 사람들이 많이 죽었다.


### Parch, SibSp - 부모자식, 형제배우자 컬럼
- 두 개의 컬럼의 데이터가 많다 -> 이 두개의 열을 하나의 컬럼으로 줄이는 작업을 한다.
- 가족이라는 컬럼을 만들어서 가족이 많은 사람/많지 않은 사람으로 나뉜다.
- 마지막에 1을 더하는 이유? 자기자신의 수가까지 포함시킨 것이다. 
- => 부모자식의 수 + 형제배우자의 수 + 자기자신 = 가족의 수
- train에도 했으니 test에도 똑같이 해준다.
- 가족의 수가 적으면 적을 수록 사망율의 높다. (혼자일때 사망율 ↑)
- 1명일 때는 죽은비율이 높고, 2~4명인 경우는 생존율이 높고, 5명 이상이면 죽은비율이 높다.
- 1부터 11까지 종류가 굉장히 많기 때문에, 새로 발견한 위의 특징을 이용해서 1명일 때는 1명에 해당하는거, 2~4까지는 하나로 뭉치고, 5부터 11까지는 하나로 뭉쳐 구간을 3개로 나눈다.
- 가족의 수가 1이면 Alone, 2~4면 Small, 5 이상이면 Large로 바꾸는 작업.
- bin이라는 리스트에 [0,1,4,11] 범위를 나눈다.
- => 0부터 1사이인데 0은 포함 X -> 1
- => 1부터 4 사이인데 1은 포함 X - > 2~4
- => 4부터 11 사이인데 4은 포함 X - > 5~11
- 이 구간에 맞는 값을 Alone과 Small과 Large를 선언해준다. -> labels
- 구간과 그 구간에 맞는 라벨까지 선언해줬으니까 이제 바꿔서 Family에 넣기만 하면 된다. -> pd.cut() 함수를 이용한다.
- train도 했으면 test도 해야한다.


# Text 데이터 다루기
- Name을 본다. 외국사람들 이름이 굉장히 길다. 이름을 스플릿 해본다.
- def(split_title) -> 행이 들어올 때 마다 (,) 콤마로 스플릿 해준다.
- 분리한 다음에 오른쪽을 택하고 (왼쪽은 버림). 첫번째꺼를 가져온다. ->[1]
- Braund, Mr. Owen Harris => Braund 와 Mr. Owen Harris 로 나뉘는데, 왼쪽 Braund는 버리고 Mr. 와 Owen Harris 로 또 나눈다. -> .split('.')[0] (0번째.)
- strip() 공백도 없앤다.
- 사람들 마다 이름이 달라 결과가 하나밖에 안나와서 유의미한 결과가 안나온다. 호칭을 기준으로 묶는다.( Mr, Ms ···)
- 새로운 컬럼 title을 만든다. train['Title'] 여기 안에 Name.apply()를 이용해 함수를 적용한다.
- 똑같이 테스트도 적용시키고 그래프까지 찍기.
- 너무 수가 많아서 plt.figure(figsize)를 조정한다.
-  Master : 결혼하지 않은 남성, 주로 청소년 이하
    Rev : 목사님(6명 모두 죽음)
    Other : 
- Mr, Mrs, Miss, Master, Rev 말고는 데이터 양이 적고 애매하다. -> 많은거 5개랑 남은거를 라벨처리한다.
- c_title로 5개와 나머지 12개 리스트로 만든다.
- title 값과 c_title 값을 둘다 매핑 시켜준다.
- 매핑을 했으니 값을 바꿔준다. train 데이터에 Title 안에 넣어준다.
- map(title_dict) -> map 함수를 쓰고 여기 안에 dictionary 형태를 넣으면 이 딕셔너리 형태에 맞게 여기안에 있는 값이 다 바뀌어진다.


# 티켓 처리
- 티켓 unique()로 처리하니까 굉장히 많다.
- 너무나도 다른 데이터가 존재하기 때문에 어떠한 연관성도 안보이는 것 같아 분석에 넣지 않는다. 컬럼이 학습에 필요없는 것 같다 판단이 들면 안 넣어도 된다. -> 드랍해버린다.
- Name을 이용해서 새로운 Title이라는 컬럼을 만들었기 때문에 Name도 드랍해버린다.


# 인코딩 작업
- 인코딩은 원핫 인코딩과 라벨 인코딩이 존재했었는데 원핫 인코딩으로 해보자.
- 인코딩 전에 X train과 Y train 으로 나눠볼건데 
- train 데이터에 Survived라는 답이 존재하고 있다. 생존과 죽음은 답인데 학습 데이터에 들어가 있다. -> 그래서 이걸 X train과 Y train 으로 나눠야한다.
- y_train() 값에 Survived를 넣는다.
- X_train()에는 Survived를 제외한 나머지를 넣는다. -> 차라리 Survived 만 드랍을 해서 지워버리면 문제만 남기 때문에.
- X_test에는 test만 넣는다. 왜 test에는 Survived 안 넣은가? 케글에서 제공하는 test 데이터에는 Survived 가 존재 X. 문제만 있기 때문에.
- 항상 문제와 답은 개수가 똑같아야 한다. X train과 Y train 두개의 관계가 똑같아야 한다. 행의 개수 같고, Y의 값은 1개니까 열이 없다. X_test의 문제는 10개의 열, X_train의 열과 일치를 해야한다. 그래야 학습이 된다.


- 원핫 인코딩을 할 때 버섯데이터는 처음부터 끝까지 문자였다. 그래서 문자를 다 넣으면 문자가 원하는 인코딩이 되는 건데, 
- 타이타닉은 모든 데이터가 문자가 아니고 숫자가 섞여있다.
- cat_feature() -> 문자로 이루어진 데이터들의 컬럼 네임즈만 뽑아온다.
- cat_feature = ['Sex','Embarked','Deck','Family','Title'] 요것들을 하나하나 원핫 인코딩을 해본다. -> 반복문으로 하나하나 자동화되게 처리한다.
- 리스트안에 있는 값이 하나하나 넘어온다.
- dummy 변수를 선언해주고, 여기서 원하는 인코딩을 처리해준다.
- train[i], prefix = i -> 원래 원핫인코딩을 진행하면 (b c d f k) 이런 값밖에 컬럼 네임으로 안나온다. prefix를 i로 설정해보면 i 가 바로 컬럼 네임이니, prefix를 넣으면 컬럼네임이 같이 나온다. (cap-shape_b) 같이.
- X_train = pd.concat(X_train, dummy) -> 이거를 X_train() 과 합친다. 원핫인코딩된 dummy를 합친다.
-  X_train() 열과 원핫인코딩으로 만들어진 컬럼이 합쳐지는데, 우리가 필요한건 원핫인코딩 컬럼이다.-> X_train()의 문자데이터를 지워준다.
-  X_test에도 똑같이 복붙해서 실행한다.
- X_train.columns -> X_train 에 대한 컬럼이 쭉 나온다. 이걸  set()에 넣으면 빠져나오는 값이 있는데, 
- set(X_train.columns) -  set(X_test.columns)
- X_test 열이랑 마이너스를 시켜서 열이 같으면 없앤다. 그렇게해서 이 두개가 같지 않은 것을이 나온다.
- X_train에 있어야할 열과 X_test에 있어야할 열이 같아야 하는데, 두개 같지 않은 열들이 존재해서,
- X_train.drop('Deck_T', axis =1, inplace = True) -> Deck의 굉장히 많은 열들이 같은게 없으니까 없애버린다. 없애고 원핫인코딩을 진행한다.
- set(X_train.columns) -  set(X_test.columns) 했을때 아무것도 안나와야 {}, 둘의 열 개수가 같은 것이고, 그래야 학습할 수 있다.
- train은 있는데 test에는 없는 경우 그러면 컬럼 개수가 달라질 수 있다. 그래서 마지막에 원핫인코딩을 진행한 후에 컬럼을 마이너스 해서 어떤게 남아있는지 확인을 하고 그것도 없애주는 작업이 필요하다.



# 모델 만들고 학습
## KNN 모델
- KNN 모델 쓰기 전에 import 해주기 
- 교차검증도 활용해보기 
- knn 모델을 변수생성해주기, 안에있는 이웃 속성은 3.(5써도 상관 없다.)
- 그냥 쓰는 게 아니라 교차검증을 써준다. 
- result 에 train 데이터(문제와 답), 데이터를 몇개로 나눌건지 써준다.(5와 10을 많이 씀)
- result의 평균이 최종적으로 나타난 학습 결과이다.





## 결정트리 
- 트리모델 생성 깊이는 5정도.
- KNN 모델거 복붙한다음 tree_model로 바꾼다.
- 결정트리에 대한 교차검증이 이루어진다.
- 이건 train데이터로 평가한 점수다. 

# 평가 
- 이렇게 만들어진 모델이 실제로 몇 %가 나올지 확인한다.
- submission에 답이 Survived 결과가 나와있는데, 여기에 기계가 예측한 답을 넣어 볼거다.
- fit을 이용해서 X_train과 Y_train 학습을 하고, X_test 로 pre 값을 예측을 한다.
- 값이 0,1,0,0,1 이렇게 나온다. 이 값을 submission csv 파일에 넣어준다.
- result['Survived'] 안에 pre 값을 넣어준다.
- 데이터프레임 파일을 csv 파일로 내보낸다. 
- 이게바로 기계가 학습한 값이 들어있는 csv 파일이다.이걸 케글에 올린다.









